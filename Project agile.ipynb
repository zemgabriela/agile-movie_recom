{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importation and understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('ml-latest-small/movies.csv', sep=',', names=['item_id', 'title', 'genres'], engine='python',skiprows=1)\n",
    "tags_df = pd.read_csv('ml-latest-small/tags.csv', sep=',', names=['user_id', 'item_id', 'tag', 'timestamp'], engine='python',skiprows=1)\n",
    "ratings_df = pd.read_csv('ml-latest-small/ratings.csv', sep=',', names=['user_id', 'item_id', 'rating', 'timestamp'], engine='python',skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MovieLens dataset is a widely-used dataset for movie recommendation systems, collected by the GroupLens research group at the University of Minnesota. It consists of multiple tables containing data about movies, ratings, and tags provided by users. Hereâ€™s a description of each table and its variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### movies_df\n",
    "- **item_id**: Unique identifier for movies.\n",
    "- **title**: The title of the movie, typically containing the release year in parentheses.\n",
    "- **genres**: A pipe-separated list of genres associated with the movie.\n",
    "\n",
    "This DataFrame contains metadata about the movies. Each movie is identified by a unique ID and has associated attributes like the title and the list of genres it belongs to. The genres are categorical and are typically used to filter or describe the content of the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9742 entries, 0 to 9741\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   item_id  9742 non-null   int64 \n",
      " 1   title    9742 non-null   object\n",
      " 2   genres   9742 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 228.5+ KB\n"
     ]
    }
   ],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tags_df\n",
    "- **user_id**: Unique identifier for users.\n",
    "- **item_id**: Unique identifier for movies which corresponds to `item_id` in `movies_df`.\n",
    "- **tag**: Textual tag provided by the user for a movie. These can be descriptive words or short phrases.\n",
    "- **timestamp**: The timestamp when the tag was provided. This is typically a Unix time stamp and indicates when the user tagged the movie.\n",
    "\n",
    "The `tags_df` table contains user-generated metadata for the movies. Each row indicates that a particular user has tagged a movie with a textual descriptor. These tags can be used for content-based filtering or to enhance the information about a movie beyond its genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3683 entries, 0 to 3682\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   user_id    3683 non-null   int64 \n",
      " 1   item_id    3683 non-null   int64 \n",
      " 2   tag        3683 non-null   object\n",
      " 3   timestamp  3683 non-null   int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 115.2+ KB\n"
     ]
    }
   ],
   "source": [
    "tags_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ratings_df\n",
    "- **user_id**: Unique identifier for users, which corresponds to `user_id` in `tags_df`.\n",
    "- **item_id**: Unique identifier for movies, consistent with `item_id` in both `movies_df` and `tags_df`.\n",
    "- **rating**: The rating given to a movie by a user. This is typically on a defined scale, like 0.5 to 5 stars.\n",
    "- **timestamp**: The timestamp when the rating was provided, in the same format as in `tags_df`.\n",
    "\n",
    "The `ratings_df` table is a record of user ratings for movies. Each row documents that a user has assigned a numerical rating to a movie. This is the core data used in collaborative filtering for recommendation systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   user_id    100836 non-null  int64  \n",
      " 1   item_id    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using these tables for building a recommendation system, one usually starts with the `ratings_df` to build the utility matrix that relates users to movies through the ratings they've provided. `movies_df` can be used to provide readable movie titles and genres for recommendations, and `tags_df` can add additional context for the movies or for more sophisticated recommendation systems that also use content-based filtering methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique movies: 9742\n",
      "Unique users in ratings: 610\n",
      "Unique movies in ratings: 9724\n",
      "Unique users in tags: 58\n",
      "Unique movies in tags: 1572\n",
      "Unique tags: 1589\n"
     ]
    }
   ],
   "source": [
    "# For movies_df to count unique movies\n",
    "unique_movies = movies_df['item_id'].nunique()\n",
    "print(f'Unique movies: {unique_movies}')\n",
    "\n",
    "# For ratings_df to count unique users and movies\n",
    "unique_users_ratings = ratings_df['user_id'].nunique()\n",
    "unique_movies_ratings = ratings_df['item_id'].nunique()\n",
    "print(f'Unique users in ratings: {unique_users_ratings}')\n",
    "print(f'Unique movies in ratings: {unique_movies_ratings}')\n",
    "\n",
    "# For tags_df to count unique users, movies, and tags\n",
    "unique_users_tags = tags_df['user_id'].nunique()\n",
    "unique_movies_tags = tags_df['item_id'].nunique()\n",
    "unique_tags = tags_df['tag'].nunique()\n",
    "print(f'Unique users in tags: {unique_users_tags}')\n",
    "print(f'Unique movies in tags: {unique_movies_tags}')\n",
    "print(f'Unique tags: {unique_tags}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first transform the columns in the table `ratings_df` to *int32*, as the recommender model needs this adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df['user_id']=ratings_df['user_id'].astype('int32')\n",
    "ratings_df['item_id']=ratings_df['item_id'].astype('int32')\n",
    "ratings_df['timestamp']=ratings_df['timestamp'].astype('int32') #It is required by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the title of the movies in the `movies_df`, creating another column for the year of the film.\n",
    "\n",
    "After that, we will get rid of the characters ', The', which are at the last part of some titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[['title', 'year']] = movies_df['title'].str.extract(r'(.+) \\((\\d{4})\\)')\n",
    "\n",
    "movies_df['title']=movies_df['title'].str.replace(', The', '')\n",
    "movies_df['genres']=movies_df['genres'].str.replace('|',', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a brief explanation of some common hyperparameters for factorization models and a suggested grid for searching:\n",
    "\n",
    "1. **n_iter**: The number of epochs to run when training the model. More epochs could lead to better performance but also increase the risk of overfitting and computational time.\n",
    "   - Suggested grid: `[1, 5, 10, 20]`\n",
    "\n",
    "2. **embedding_dim**: The size of the latent feature vectors for users and items. Larger dimensions could capture more complex patterns but might overfit.\n",
    "   - Suggested grid: `[8, 16, 32, 64]`\n",
    "\n",
    "3. **learning_rate**: The step size at each iteration of the optimization algorithm. A smaller learning rate could lead to more precise convergence but might require more epochs.\n",
    "   - Suggested grid: `[0.001, 0.01, 0.1]`\n",
    "\n",
    "4. **l2**: The L2 regularization penalty. Higher values could prevent overfitting but might lead to underfitting if too large.\n",
    "   - Suggested grid: `[0.0, 1e-6, 1e-5, 1e-3]`\n",
    "\n",
    "5. **loss**: The loss function to be used. Common options are `pointwise`, `bpr`, or `hinge` loss, which are suitable for different types of recommendation tasks.\n",
    "   - Suggested values: `['pointwise', 'bpr', 'hinge']`\n",
    "\n",
    "6. **batch_size**: The number of samples per gradient update. Larger batches provide more accurate estimates of the gradient, but smaller batches might help the model to generalize better.\n",
    "   - Suggested grid: `[32, 64, 128, 256]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 4.380506869695839\n",
      "Epoch 1: loss 0.8117601574117631\n",
      "Epoch 2: loss 0.5160774380269205\n",
      "Epoch 3: loss 0.3599795619661336\n",
      "Epoch 4: loss 0.2889907266100333\n"
     ]
    }
   ],
   "source": [
    "from spotlight.interactions import Interactions\n",
    "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "\n",
    "# Step 2: Create the Interactions object\n",
    "interaction_data = Interactions(\n",
    "    user_ids=ratings_df['user_id'].values,\n",
    "    item_ids=ratings_df['item_id'].values,\n",
    "    ratings=ratings_df['rating'].values,\n",
    "    timestamps=ratings_df['timestamp'].values\n",
    ")\n",
    "\n",
    "# Split the interaction data into training and test sets\n",
    "train, test = random_train_test_split(interaction_data)\n",
    "\n",
    "# Initialize the model\n",
    "model = ExplicitFactorizationModel(\n",
    "    n_iter=5,           # Number of epochs of training\n",
    "    embedding_dim=32,   # Latent factors (embedding size)\n",
    "    use_cuda=False      # If you have a CUDA capable GPU, set to True to speed up training\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE 0.474, test RMSE 1.051\n"
     ]
    }
   ],
   "source": [
    "from spotlight.evaluation import rmse_score\n",
    "\n",
    "train_rmse = rmse_score(model, train)\n",
    "test_rmse = rmse_score(model, test)\n",
    "\n",
    "print('Train RMSE {:.3f}, test RMSE {:.3f}'.format(train_rmse, test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R1: Community recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a tag, a list of popular tags and a number of films (n), it returns the most *n* recommended films (ordered by rating) in the tag provided.\n",
    "\n",
    "If the tag is not in the popular tags list, it returns an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag\n",
       "In Netflix queue     131\n",
       "atmospheric           36\n",
       "thought-provoking     24\n",
       "superhero             24\n",
       "funny                 23\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We first filter popular tags, which have more than 15 users\n",
    "counter_tag= tags_df['tag'].value_counts()\n",
    "popular_tag = counter_tag[counter_tag > 15]\n",
    "popular_tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_recommender(tag,popular_tag,n):\n",
    "    popular_tag = [t.lower() for t in popular_tag.index] \n",
    "    tag=tag.lower() # convert everything in lower\n",
    "    if tag in popular_tag:\n",
    "        movie_filtered_by_tag = tags_df[tags_df['tag'].str.lower() == tag]\n",
    "        movie_list = movie_filtered_by_tag['item_id'] #we extract here the movies that has this tag\n",
    "        movies_filtered = ratings_df[ratings_df['item_id'].isin(movie_list)].groupby(['item_id'])['rating'].mean().reset_index() #here we focuse on those movies and then we extract the mean rating.\n",
    "        movies_filtered.sort_values(by='rating', ascending=False, inplace=True)  #we sort them \n",
    "        top_movie_ids = movies_filtered.iloc[0:n]['item_id'] #here we extract the first n movies\n",
    "        recommended_movies = movies_df[movies_df['item_id'].isin(top_movie_ids)]['title'].values.tolist() #we extract the movies with that id\n",
    "        return recommended_movies\n",
    "    else:\n",
    "        return 'No matches based on your research'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usual Suspects\n",
      "Pulp Fiction\n",
      "Terminator 2: Judgment Day\n",
      "Silence of the Lambs\n",
      "Shining\n",
      "Rosemary's Baby\n",
      "Departed\n",
      "Inception\n",
      "Captain Phillips\n",
      "Whiplash\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(community_recommender('suspense',popular_tag,10))) #Example of how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R2: Rating prediction given a user and a movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a user_id and a movie_title, it predicts the rating for the given movie and user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user 1 and movie 'Silence of the Lambs': 4.186103820800781\n"
     ]
    }
   ],
   "source": [
    "def predict_rating_for_user_and_movie_title(model, user_id, movie_title, movies_df):\n",
    "    # Find the item ID for the given movie title\n",
    "    item_id = movies_df[movies_df['title'] == movie_title]['item_id'].values\n",
    "    \n",
    "    # If the movie title is not found, return a message indicating so\n",
    "    if item_id.size == 0:\n",
    "        return \"Movie title not found.\"\n",
    "    \n",
    "    # Assuming the first match is the correct one\n",
    "    item_id = item_id[0]\n",
    "    \n",
    "    # Predict scores for all items for the user\n",
    "    predictions = model.predict(user_ids=np.array([user_id]))\n",
    "    \n",
    "    # If the item ID is not in the mapping, return a message indicating the item was not found\n",
    "    if item_id is None:\n",
    "        return \"Item ID not found in the mapping.\"\n",
    "    \n",
    "    # Extract the prediction for the specific item\n",
    "    predicted_rating = predictions[item_id]\n",
    "    \n",
    "    return predicted_rating\n",
    "\n",
    "# Example usage:\n",
    "user_id = 1\n",
    "movie_title = \"Silence of the Lambs\"\n",
    "predicted_rating = predict_rating_for_user_and_movie_title(model, user_id, movie_title, movies_df)\n",
    "print(f\"Predicted rating for user {user_id} and movie '{movie_title}': {predicted_rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R3: N recommended movies given a user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a user_id and number of recommendations (n), it returns the *n* recommended movies for that user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommended_movies_by_user(model, user_id, n_movies):\n",
    "    pred=model.predict(user_ids=user_id)\n",
    "    sorted_indices = np.argsort(pred)[::-1] #we sort the indices \n",
    "    top_indices = sorted_indices[:n_movies]+1 #we extract the top n_movies. Now we have to extract the title of the associated movies to give the recommendation\n",
    "    recommended_movies = movies_df[movies_df['item_id'].isin(top_indices)]['title'].values.tolist() #we extract the movies with that id\n",
    "    return recommended_movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trust',\n",
       " 'Manhattan',\n",
       " \"Jumpin' Jack Flash\",\n",
       " 'Fright Night Part II',\n",
       " 'Phantasm II']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_movies_by_user(model=model, user_id=1, n_movies=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R4: N recommended movies for unseen users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a list of movies the user has seen and like, it returns the *n* movies most recommended, similar to the movies the user pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For that, we need another model which takes as input a list of movies, rather than a user_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight.cross_validation import user_based_train_test_split\n",
    "\n",
    "train, test = user_based_train_test_split(interaction_data)\n",
    "\n",
    "train = train.to_sequence()\n",
    "test = test.to_sequence()\n",
    "model_seq = ImplicitSequenceModel(n_iter=5,\n",
    "                                  representation='cnn',\n",
    "                                  loss='bpr')\n",
    "model_seq.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Speed',\n",
       " 'X-Men',\n",
       " 'Crouching Tiger, Hidden Dragon (Wo hu cang long)',\n",
       " 'My Big Fat Greek Wedding',\n",
       " 'Zombieland']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_next_movies(list_of_movies,model,n_movies): #list_of_movies=titles of movies watched \n",
    "    #we firstly check if the titles are in the movie list and remove the ones that are not present. \n",
    "    #We also convert the titles in order to avoid uppercase sensibility (e.g. spiderman, Spiderman)\n",
    "    list_of_movies = [title.lower() for title in list_of_movies]\n",
    "    list_of_movies = [title for title in list_of_movies if title in movies_df['title'].str.lower().tolist()]\n",
    "    if not list_of_movies: #we check if it is empty\n",
    "        return 'The list of films provided is not in the catalogue' \n",
    "    indices_movies=movies_df[movies_df['title'].str.lower().isin(list_of_movies)]['item_id']\n",
    "    pred=model.predict(sequences=np.array(indices_movies))\n",
    "    sorted_indices = np.argsort(pred)[::-1]\n",
    "    top_indices = sorted_indices[:n_movies]\n",
    "    recommended_movies = movies_df[movies_df['item_id'].isin(top_indices)]['title'].values.tolist() \n",
    "    return recommended_movies\n",
    "\n",
    "list_movies = ['Toy Story', 'Jumanji', 'Grumpier Old Men']\n",
    "\n",
    "recommend_next_movies(list_movies, model_seq, 5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
